diff --git a/tensorflow/compiler/xla/rpc/BUILD b/tensorflow/compiler/xla/rpc/BUILD
index 97fcd37f6b..35bcd357c3 100644
--- a/tensorflow/compiler/xla/rpc/BUILD
+++ b/tensorflow/compiler/xla/rpc/BUILD
@@ -34,6 +34,62 @@ cc_library(
     ],
 )
 
+load("//tensorflow:tensorflow.bzl", "tf_cc_shared_object")
+
+tf_cc_shared_object(
+    name = "libxla_computation_client.so",
+    visibility = ["//visibility:public"],
+    linkopts = select({
+        "//tensorflow:darwin": [
+            "-Wl,-exported_symbols_list",  # This line must be directly followed by the exported_symbols.lds file
+            "//tensorflow:tf_exported_symbols.lds",
+        ],
+        "//tensorflow:windows": [],
+        "//conditions:default": [
+            "-z defs",
+            "-s",
+            "-Wl,--version-script",  #  This line must be directly followed by the version_script.lds file
+            "//tensorflow:tf_version_script.lds",
+        ],
+    }),
+    deps = [
+        "@com_google_absl//absl/strings",
+        "//tensorflow:tf_exported_symbols.lds",
+        "//tensorflow:tf_version_script.lds",
+        "computation_client_impl",
+        "grpc_stub",
+        "//tensorflow/compiler/xla:literal_util",
+        "//tensorflow/compiler/xla/client",
+        "//tensorflow/compiler/xla/client:xla_builder",
+        "//tensorflow/compiler/xla/client:global_data",
+        "//tensorflow/compiler/xla/client:xla_computation",
+        "//tensorflow/core:lib",
+    ],
+)
+
+cc_library(
+    name = "computation_client_impl",
+    srcs = ["computation_client.cc"],
+    hdrs = ["computation_client.h"],
+    deps = [
+        "grpc_stub",
+        "@com_google_absl//absl/strings",
+        "//tensorflow/cc:cc_ops",
+        "//tensorflow/cc:client_session",
+        "//tensorflow/cc:ops",
+        "//tensorflow/cc:scope",
+        "//tensorflow/compiler/xla:literal_util",
+        "//tensorflow/compiler/xla/client",
+        "//tensorflow/compiler/xla/client:global_data",
+        "//tensorflow/compiler/xla/client:xla_computation",
+        "//tensorflow/compiler/xrt:xrt_proto",
+        "//tensorflow/compiler/xrt:xrt_server",
+        "//tensorflow/compiler/xrt/cc:xrt_ops",
+        "//tensorflow/core:lib",
+        "//tensorflow/core/kernels:conv_ops",
+    ],
+)
+
 tf_cc_binary(
     name = "grpc_service_main_cpu",
     srcs = ["grpc_service_main.cc"],
diff --git a/tensorflow/compiler/xla/rpc/computation_client.cc b/tensorflow/compiler/xla/rpc/computation_client.cc
new file mode 100644
index 0000000000..2de4c5b6fc
--- /dev/null
+++ b/tensorflow/compiler/xla/rpc/computation_client.cc
@@ -0,0 +1,103 @@
+#include "tensorflow/compiler/xla/rpc/computation_client.h"
+#include "tensorflow/cc/framework/ops.h"
+#include "tensorflow/cc/framework/scope.h"
+#include "tensorflow/cc/ops/const_op.h"
+#include "tensorflow/compiler/xrt/cc/ops/xrt_execute_op.h"
+#include "tensorflow/compiler/xrt/cc/ops/xrt_state_ops.h"
+#include "tensorflow/compiler/xrt/xrt.pb.h"
+
+namespace xla {
+
+class XlaComputationClientImpl {
+ public:
+  XlaComputationClientImpl();
+
+  std::unique_ptr<::tensorflow::Output> TransferParameterToServer(
+      const xla::Literal& literal) const;
+
+  std::unique_ptr<::tensorflow::Output> ExecuteComputation(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const;
+
+  std::unique_ptr<Literal> ExecuteComputationAndTransfer(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const;
+
+  StatusOr<std::vector<std::unique_ptr<::tensorflow::Output>>> DeconstructTuple(
+      const ::tensorflow::Output& data) const;
+};
+
+XlaComputationClientImpl::XlaComputationClientImpl() {}
+
+namespace {
+
+std::string DeviceFromFlag() { return "/device:CPU:0"; }
+
+}  // namespace
+
+std::unique_ptr<::tensorflow::Output>
+XlaComputationClientImpl::TransferParameterToServer(
+    const xla::Literal& literal) const {
+  xrt::XLAAllocation alloc;
+  alloc.set_device_ordinal(0);
+  *alloc.mutable_value() = literal.ToProto();
+  ::tensorflow::Scope root =
+      ::tensorflow::Scope::NewRootScope().WithDevice(DeviceFromFlag());
+  auto value = ::tensorflow::ops::Const(root.WithDevice("/device:CPU:0"),
+                                        alloc.SerializeAsString());
+  auto handle = ::tensorflow::ops::XRTAllocate(root, value);
+  return std::unique_ptr<::tensorflow::Output>(
+      new ::tensorflow::Output(handle));
+}
+
+std::unique_ptr<::tensorflow::Output>
+XlaComputationClientImpl::ExecuteComputation(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const {
+  ::tensorflow::Scope root =
+      ::tensorflow::Scope::NewRootScope().WithDevice(DeviceFromFlag());
+  return nullptr;
+}
+
+std::unique_ptr<Literal>
+XlaComputationClientImpl::ExecuteComputationAndTransfer(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const {
+  return nullptr;
+}
+
+StatusOr<std::vector<std::unique_ptr<::tensorflow::Output>>>
+XlaComputationClientImpl::DeconstructTuple(
+    const ::tensorflow::Output& data) const {
+  return std::vector<std::unique_ptr<::tensorflow::Output>>{};
+}
+
+XlaComputationClient::XlaComputationClient()
+    : pImpl(new XlaComputationClientImpl()) {}
+
+std::unique_ptr<::tensorflow::Output> XlaComputationClient::ExecuteComputation(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const {
+  return pImpl->ExecuteComputation(computation, arguments);
+}
+
+std::unique_ptr<Literal> XlaComputationClient::ExecuteComputationAndTransfer(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const {
+  return pImpl->ExecuteComputationAndTransfer(computation, arguments);
+}
+
+StatusOr<std::vector<std::unique_ptr<::tensorflow::Output>>>
+XlaComputationClient::DeconstructTuple(const ::tensorflow::Output& data) const {
+  return pImpl->DeconstructTuple(data);
+}
+
+std::unique_ptr<::tensorflow::Output>
+XlaComputationClient::TransferParameterToServer(
+    const xla::Literal& literal) const {
+  return pImpl->TransferParameterToServer(literal);
+}
+
+XlaComputationClient::~XlaComputationClient() = default;
+
+}  // namespace xla
diff --git a/tensorflow/compiler/xla/rpc/computation_client.h b/tensorflow/compiler/xla/rpc/computation_client.h
new file mode 100644
index 0000000000..89f4f93a6c
--- /dev/null
+++ b/tensorflow/compiler/xla/rpc/computation_client.h
@@ -0,0 +1,39 @@
+#ifndef TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
+#define TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
+
+#include "tensorflow/cc/framework/ops.h"
+#include "tensorflow/compiler/xla/client/xla_computation.h"
+#include "tensorflow/compiler/xla/literal_util.h"
+#include "tensorflow/core/lib/gtl/array_slice.h"
+
+namespace xla {
+
+class XlaComputationClientImpl;
+
+class XlaComputationClient {
+ public:
+  XlaComputationClient();
+
+  ~XlaComputationClient();
+
+  std::unique_ptr<::tensorflow::Output> TransferParameterToServer(
+      const xla::Literal& literal) const;
+
+  std::unique_ptr<::tensorflow::Output> ExecuteComputation(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const;
+
+  std::unique_ptr<Literal> ExecuteComputationAndTransfer(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<::tensorflow::Output*> arguments) const;
+
+  StatusOr<std::vector<std::unique_ptr<::tensorflow::Output>>> DeconstructTuple(
+      const ::tensorflow::Output& data) const;
+
+ private:
+  std::unique_ptr<XlaComputationClientImpl> pImpl;
+};
+
+}  // namespace xla
+
+#endif  // TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
diff --git a/tensorflow/compiler/xla/rpc/grpc_service_main.cc b/tensorflow/compiler/xla/rpc/grpc_service_main.cc
index d6b5149a24..e2a506b6b8 100644
--- a/tensorflow/compiler/xla/rpc/grpc_service_main.cc
+++ b/tensorflow/compiler/xla/rpc/grpc_service_main.cc
@@ -48,6 +48,7 @@ int RealMain(int argc, char** argv) {
 
   builder.AddListeningPort(server_address, ::grpc::InsecureServerCredentials());
   builder.RegisterService(service.get());
+  builder.SetMaxReceiveMessageSize(INT_MAX);
   std::unique_ptr<::grpc::Server> server(builder.BuildAndStart());
 
   LOG(INFO) << "Server listening on " << server_address;
diff --git a/tensorflow/tf_exported_symbols.lds b/tensorflow/tf_exported_symbols.lds
index 3ff824e5e1..2a47055ac3 100644
--- a/tensorflow/tf_exported_symbols.lds
+++ b/tensorflow/tf_exported_symbols.lds
@@ -5,3 +5,5 @@
 *TFE_*
 *nsync_*
 *pywrap_xla*
+*xla*
+*ConvBackpropComputeDimensionsV2*
diff --git a/tensorflow/tf_version_script.lds b/tensorflow/tf_version_script.lds
index 6b28943f01..6eacc2db99 100644
--- a/tensorflow/tf_version_script.lds
+++ b/tensorflow/tf_version_script.lds
@@ -6,6 +6,8 @@ tensorflow {
     *TFE_*;
     *nsync_*;
     *pywrap_xla*;
+    *xla*;
+    *ConvBackpropComputeDimensionsV2*;
   local:
     *;
 };
