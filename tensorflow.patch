diff --git a/tensorflow/compiler/xla/rpc/BUILD b/tensorflow/compiler/xla/rpc/BUILD
index 0d56a9a477..fd8353134d 100644
--- a/tensorflow/compiler/xla/rpc/BUILD
+++ b/tensorflow/compiler/xla/rpc/BUILD
@@ -34,6 +34,56 @@ cc_library(
     ],
 )

+load("//tensorflow:tensorflow.bzl", "tf_cc_shared_object")
+
+tf_cc_shared_object(
+    name = "libxla_computation_client.so",
+    visibility = ["//visibility:public"],
+    linkopts = select({
+        "//tensorflow:darwin": [
+            "-Wl,-exported_symbols_list",  # This line must be directly followed by the exported_symbols.lds file
+            "//tensorflow:tf_exported_symbols.lds",
+        ],
+        "//tensorflow:windows": [],
+        "//tensorflow:windows_msvc": [],
+        "//conditions:default": [
+            "-z defs",
+            "-s",
+            "-Wl,--version-script",  #  This line must be directly followed by the version_script.lds file
+            "//tensorflow:tf_version_script.lds",
+        ],
+    }),
+    deps = [
+        "//tensorflow:tf_exported_symbols.lds",
+        "//tensorflow:tf_version_script.lds",
+        "computation_client_impl",
+        "grpc_stub",
+        "//tensorflow/compiler/xla:literal_util",
+        "//tensorflow/compiler/xla/client",
+        "//tensorflow/compiler/xla/client/xla_client:xla_builder",
+        "//tensorflow/compiler/xla/client:global_data",
+        "//tensorflow/compiler/xla/client/xla_client:xla_computation",
+        "//tensorflow/core:lib",
+        "@grpc//:grpc++_unsecure",
+    ],
+)
+
+cc_library(
+    name = "computation_client_impl",
+    srcs = ["computation_client.cc"],
+    hdrs = ["computation_client.h"],
+    deps = [
+        "grpc_stub",
+        "@grpc//:grpc++_unsecure",
+        "//tensorflow/compiler/xla:literal_util",
+        "//tensorflow/compiler/xla/client",
+        "//tensorflow/compiler/xla/client:global_data",
+        "//tensorflow/compiler/xla/client/xla_client:xla_computation",
+        "//tensorflow/core:lib",
+        "//tensorflow/core/kernels:conv_ops",
+    ],
+)
+
 tf_cc_binary(
     name = "grpc_service_main_cpu",
     srcs = ["grpc_service_main.cc"],
diff --git a/tensorflow/compiler/xla/rpc/computation_client.cc b/tensorflow/compiler/xla/rpc/computation_client.cc
new file mode 100644
index 0000000000..152d0304ca
--- /dev/null
+++ b/tensorflow/compiler/xla/rpc/computation_client.cc
@@ -0,0 +1,79 @@
+#include "tensorflow/compiler/xla/rpc/computation_client.h"
+#include "grpc++/create_channel.h"
+#include "grpc++/support/channel_arguments.h"
+#include "tensorflow/compiler/xla/client/client.h"
+#include "tensorflow/compiler/xla/legacy_flags/debug_options_flags.h"
+#include "tensorflow/compiler/xla/rpc/grpc_stub.h"
+
+namespace xla {
+
+class XlaComputationClientImpl {
+ public:
+  XlaComputationClientImpl();
+
+  std::unique_ptr<xla::GlobalData> TransferParameterToServer(
+      const xla::Literal& literal) const;
+
+  std::unique_ptr<Literal> ExecuteComputation(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<GlobalData*> arguments) const;
+
+ private:
+  std::unique_ptr<Client> client_;
+  std::unique_ptr<grpc::XlaService::Stub> xla_service_;
+  std::unique_ptr<GRPCStub> stub_;
+};
+
+XlaComputationClientImpl::XlaComputationClientImpl() {
+  constexpr int port = 51000;
+  ::grpc::ChannelArguments ch_args;
+  ch_args.SetMaxReceiveMessageSize(-1);
+  auto channel = ::grpc::CreateCustomChannel(
+      tensorflow::strings::Printf("localhost:%d", port),
+      ::grpc::InsecureChannelCredentials(), ch_args);
+  channel->WaitForConnected(gpr_time_add(
+      gpr_now(GPR_CLOCK_REALTIME), gpr_time_from_seconds(10, GPR_TIMESPAN)));
+  LOG(INFO) << "Channel to server is connected on port " << port;
+
+  xla_service_ = grpc::XlaService::NewStub(channel);
+  stub_.reset(new GRPCStub(xla_service_.get()));
+  client_.reset(new Client(stub_.get()));
+}
+
+std::unique_ptr<Literal> XlaComputationClientImpl::ExecuteComputation(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<GlobalData*> arguments) const {
+  ExecutionOptions eo;
+  *eo.mutable_debug_options() = legacy_flags::GetDebugOptionsFromFlags();
+  StatusOr<std::unique_ptr<Literal>> result_or_status =
+      client_->ExecuteAndTransfer(computation, arguments, &eo);
+  if (!result_or_status.ok()) {
+    LOG(FATAL) << result_or_status.status();
+  }
+  return std::move(result_or_status.ValueOrDie());
+}
+
+std::unique_ptr<xla::GlobalData>
+XlaComputationClientImpl::TransferParameterToServer(
+    const xla::Literal& literal) const {
+  return client_->TransferToServer(literal).ValueOrDie();
+}
+
+XlaComputationClient::XlaComputationClient()
+    : pImpl(new XlaComputationClientImpl()) {}
+
+std::unique_ptr<Literal> XlaComputationClient::ExecuteComputation(
+    const XlaComputation& computation,
+    tensorflow::gtl::ArraySlice<GlobalData*> arguments) const {
+  return pImpl->ExecuteComputation(computation, arguments);
+}
+
+std::unique_ptr<xla::GlobalData>
+XlaComputationClient::TransferParameterToServer(
+    const xla::Literal& literal) const {
+  return pImpl->TransferParameterToServer(literal);
+}
+
+XlaComputationClient::~XlaComputationClient() = default;
+
+}  // namespace xla
diff --git a/tensorflow/compiler/xla/rpc/computation_client.h b/tensorflow/compiler/xla/rpc/computation_client.h
new file mode 100644
index 0000000000..961e93f168
--- /dev/null
+++ b/tensorflow/compiler/xla/rpc/computation_client.h
@@ -0,0 +1,32 @@
+#ifndef TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
+#define TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
+
+#include "tensorflow/compiler/xla/client/global_data.h"
+#include "tensorflow/compiler/xla/client/xla_client/xla_computation.h"
+#include "tensorflow/compiler/xla/literal_util.h"
+#include "tensorflow/core/lib/gtl/array_slice.h"
+
+namespace xla {
+
+class XlaComputationClientImpl;
+
+class XlaComputationClient {
+ public:
+  XlaComputationClient();
+
+  ~XlaComputationClient();
+
+  std::unique_ptr<xla::GlobalData> TransferParameterToServer(
+      const xla::Literal& literal) const;
+
+  std::unique_ptr<Literal> ExecuteComputation(
+      const XlaComputation& computation,
+      tensorflow::gtl::ArraySlice<GlobalData*> arguments) const;
+
+ private:
+  std::unique_ptr<XlaComputationClientImpl> pImpl;
+};
+
+}  // namespace xla
+
+#endif  // TENSORFLOW_COMPILER_XLA_RPC_COMPUTATION_CLIENT_H_
diff --git a/tensorflow/compiler/xla/rpc/grpc_service_main.cc b/tensorflow/compiler/xla/rpc/grpc_service_main.cc
index c68c857c30..7110c7065e 100644
--- a/tensorflow/compiler/xla/rpc/grpc_service_main.cc
+++ b/tensorflow/compiler/xla/rpc/grpc_service_main.cc
@@ -48,6 +48,7 @@ int RealMain(int argc, char** argv) {
 
   builder.AddListeningPort(server_address, ::grpc::InsecureServerCredentials());
   builder.RegisterService(service.get());
+  builder.SetMaxReceiveMessageSize(INT_MAX);
   std::unique_ptr<::grpc::Server> server(builder.BuildAndStart());
 
   LOG(INFO) << "Server listening on " << server_address;
diff --git a/tensorflow/tf_exported_symbols.lds b/tensorflow/tf_exported_symbols.lds
index 3ff824e5e1..39d1728b01 100644
--- a/tensorflow/tf_exported_symbols.lds
+++ b/tensorflow/tf_exported_symbols.lds
@@ -5,3 +5,5 @@
 *TFE_*
 *nsync_*
 *pywrap_xla*
+*xla*
+*ConvBackpropComputeDimensionsV2*
diff --git a/tensorflow/tf_version_script.lds b/tensorflow/tf_version_script.lds
index 6b28943f01..76b7454c35 100644
--- a/tensorflow/tf_version_script.lds
+++ b/tensorflow/tf_version_script.lds
@@ -6,6 +6,8 @@ tensorflow {
     *TFE_*;
     *nsync_*;
     *pywrap_xla*;
+    *xla*;
+    *ConvBackpropComputeDimensionsV2*;
   local:
     *;
 };
